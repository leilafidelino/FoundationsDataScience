{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, classification_report, log_loss, jaccard_similarity_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('df_train.csv', index_col = 0)\n",
    "df_test = pd.read_csv('df_test.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: (165646, 14) (165646,)\n"
     ]
    }
   ],
   "source": [
    "#Test set\n",
    "X_test = df_test.drop(['P_ISEV'], axis =1).values\n",
    "Y_test = df_test['P_ISEV'].values\n",
    "print ('Test set:', X_test.shape,  Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample the majority classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    1890\n",
      "2    1890\n",
      "1    1890\n",
      "Name: P_ISEV, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "X2 = df_train  # orginal train data will be used for resampling (labeled as X2)\n",
    "\n",
    "# separate minority and majority classes\n",
    "no_injury = X2[X2.P_ISEV==1]\n",
    "injury = X2[X2.P_ISEV==2]\n",
    "fatal = X2[X2.P_ISEV==3]\n",
    "\n",
    "# downsample majority\n",
    "no_injury_downsampled = resample(no_injury,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(fatal), # match minority n\n",
    "                                random_state = 16) # reproducible results\n",
    "\n",
    "injury_downsampled = resample(injury,\n",
    "                                replace = False, \n",
    "                                n_samples = len(fatal),\n",
    "                                random_state = 16)\n",
    "\n",
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([no_injury_downsampled, injury_downsampled, fatal])\n",
    "\n",
    "# checking counts\n",
    "print(downsampled.P_ISEV.value_counts())\n",
    "\n",
    "#Prepare data\n",
    "Y2 = downsampled['P_ISEV'].values\n",
    "X2 = (downsampled.drop('P_ISEV', axis=1)).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (4536, 14) (4536,)\n",
      "Validation set: (1134, 14) (1134,)\n"
     ]
    }
   ],
   "source": [
    "# Split the upsampled train data into train and validation sets\n",
    "X2_train, X2_validate, Y2_train, Y2_validate = train_test_split( X2, Y2, test_size=0.2, random_state= 4) \n",
    "print ('Train set:', X2_train.shape,  Y2_train.shape)\n",
    "print ('Validation set:', X2_validate.shape,  Y2_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Log Regression's accuracy_score:  0.5194003527336861\n",
      "Multinomial Log Regression's f1_score:  0.5145175780578803\n",
      "Multinomial Log Regression's recall_score:  0.5194003527336861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.53      0.53       371\n",
      "           2       0.44      0.37      0.40       364\n",
      "           3       0.57      0.64      0.60       399\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      1134\n",
      "   macro avg       0.51      0.52      0.51      1134\n",
      "weighted avg       0.51      0.52      0.51      1134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "#train model\n",
    "downsampledMLR = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg').fit(X2_train, Y2_train)\n",
    "\n",
    "#Validate\n",
    "downsampledMLR_validate = downsampledMLR.predict(X2_validate)\n",
    "\n",
    "#Predict on test set\n",
    "downsampledMLR_pred = downsampledMLR.predict(X_test)\n",
    "\n",
    "# Checking accuracy of validation set\n",
    "print(\"Multinomial Log Regression's accuracy_score: \", accuracy_score(Y2_validate, downsampledMLR_validate))\n",
    "print(\"Multinomial Log Regression's f1_score: \", f1_score(Y2_validate, downsampledMLR_validate, average = 'weighted'))\n",
    "print(\"Multinomial Log Regression's recall_score: \", recall_score(Y2_validate, downsampledMLR_validate, average = 'weighted'))\n",
    "print (classification_report(Y2_validate, downsampledMLR_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Log Regression's accuracy_score:  0.46040954807239537\n",
      "Multinomial Log Regression's f1_score:  0.5171103238221793\n",
      "Multinomial Log Regression's recall_score:  0.46040954807239537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.52      0.54     70849\n",
      "           2       0.66      0.41      0.51     93875\n",
      "           3       0.01      0.65      0.03       922\n",
      "\n",
      "   micro avg       0.46      0.46      0.46    165646\n",
      "   macro avg       0.41      0.53      0.36    165646\n",
      "weighted avg       0.61      0.46      0.52    165646\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking accuracy of test set\n",
    "print(\"Multinomial Log Regression's accuracy_score: \", accuracy_score(Y_test, downsampledMLR_pred))\n",
    "print(\"Multinomial Log Regression's f1_score: \", f1_score(Y_test, downsampledMLR_pred, average = 'weighted'))\n",
    "print(\"Multinomial Log Regression's recall_score: \", recall_score(Y_test, downsampledMLR_pred, average = 'weighted'))\n",
    "print(classification_report(Y_test, downsampledMLR_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest's accuracy_score:  0.591710758377425\n",
      "Random Forest's f1_score:  0.5861974234059729\n",
      "Random Forest's recall_score:  0.591710758377425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.60      0.58       371\n",
      "           2       0.47      0.40      0.43       364\n",
      "           3       0.71      0.76      0.73       399\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      1134\n",
      "   macro avg       0.58      0.59      0.58      1134\n",
      "weighted avg       0.58      0.59      0.59      1134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# train model\n",
    "downsampledRFC = RandomForestClassifier(n_estimators=100).fit(X2_train, Y2_train)\n",
    "\n",
    "#Validate\n",
    "downsampledRFC_validate = downsampledRFC.predict(X2_validate)\n",
    "\n",
    "# Predict on test set\n",
    "downsampledRFC_pred = downsampledRFC.predict(X_test)\n",
    "\n",
    "# Checking accuracy of validation set\n",
    "print(\"Random Forest's accuracy_score: \", accuracy_score(Y2_validate, downsampledRFC_validate))\n",
    "print(\"Random Forest's f1_score: \", f1_score(Y2_validate, downsampledRFC_validate, average = 'weighted'))\n",
    "print(\"Random Forest's recall_score: \", recall_score(Y2_validate, downsampledRFC_validate, average = 'weighted'))\n",
    "print (classification_report(Y2_validate, downsampledRFC_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest's accuracy_score:  0.500501068543762\n",
      "Random Forest's f1_score:  0.5355010740958787\n",
      "Random Forest's recall_score:  0.500501068543762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.62      0.58     70849\n",
      "           2       0.66      0.41      0.51     93875\n",
      "           3       0.02      0.73      0.05       922\n",
      "\n",
      "   micro avg       0.50      0.50      0.50    165646\n",
      "   macro avg       0.41      0.59      0.38    165646\n",
      "weighted avg       0.61      0.50      0.54    165646\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking accuracy of test set\n",
    "print(\"Random Forest's accuracy_score: \", accuracy_score(Y_test, downsampledRFC_pred))\n",
    "print(\"Random Forest's f1_score: \", f1_score(Y_test, downsampledRFC_pred, average = 'weighted'))\n",
    "print(\"Random Forest's recall_score: \", recall_score(Y_test, downsampledRFC_pred, average = 'weighted'))\n",
    "print (classification_report(Y_test, downsampledRFC_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTrees's accuracy_score:  0.5546737213403881\n",
      "DecisionTrees's f1_score: 0.53315653569139\n",
      "DecisionTrees's recall_score: 0.5546737213403881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.74      0.57       371\n",
      "           2       0.52      0.23      0.32       364\n",
      "           3       0.71      0.68      0.69       399\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      1134\n",
      "   macro avg       0.56      0.55      0.53      1134\n",
      "weighted avg       0.57      0.55      0.53      1134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#train the model\n",
    "downsampledDTC = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4).fit(X2_train,Y2_train)\n",
    "\n",
    "#Validate\n",
    "downsampledDTC_validate = downsampledDTC.predict(X2_validate)\n",
    "\n",
    "#Predict on test set\n",
    "downsampledDTC_pred = downsampledDTC.predict(X_test)\n",
    "\n",
    "#Check accuracy of the validation set\n",
    "print(\"DecisionTrees's accuracy_score: \", accuracy_score(Y2_validate, downsampledDTC_validate))\n",
    "print(\"DecisionTrees's f1_score:\" , f1_score(Y2_validate, downsampledDTC_validate, average = 'weighted'))\n",
    "print(\"DecisionTrees's recall_score:\" , recall_score(Y2_validate, downsampledDTC_validate, average = 'weighted'))\n",
    "print (classification_report(Y2_validate, downsampledDTC_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTrees's accuracy_score:  0.44503338444634943\n",
      "DecisionTrees's f1_score: 0.43891713006260685\n",
      "DecisionTrees's recall_score: 0.44503338444634943\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.75      0.59     70849\n",
      "           2       0.65      0.22      0.33     93875\n",
      "           3       0.02      0.64      0.04       922\n",
      "\n",
      "   micro avg       0.45      0.45      0.45    165646\n",
      "   macro avg       0.39      0.53      0.32    165646\n",
      "weighted avg       0.58      0.45      0.44    165646\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check accuracy of the test set\n",
    "print(\"DecisionTrees's accuracy_score: \", accuracy_score(Y_test, downsampledDTC_pred))\n",
    "print(\"DecisionTrees's f1_score:\" , f1_score(Y_test, downsampledDTC_pred, average = 'weighted'))\n",
    "print(\"DecisionTrees's recall_score:\" , recall_score(Y_test, downsampledDTC_pred, average = 'weighted'))\n",
    "print (classification_report(Y_test, downsampledDTC_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set Accuracy:  0.42707339748620554\n",
      "Random Forest Classifier's f1_score:  0.45611900705444536\n",
      "Random Forest Classifier's recall_score:  0.42707339748620554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.60      0.55     70849\n",
      "           2       0.60      0.29      0.39     93875\n",
      "           3       0.02      0.69      0.04       922\n",
      "\n",
      "   micro avg       0.43      0.43      0.43    165646\n",
      "   macro avg       0.37      0.53      0.32    165646\n",
      "weighted avg       0.55      0.43      0.46    165646\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k = 30\n",
    "downsampledKNC = KNeighborsClassifier(n_neighbors = k).fit(X2_train,Y2_train)\n",
    "\n",
    "#Predict \n",
    "downsampledKNC_pred = downsampledKNC.predict(X_test)\n",
    "\n",
    "#Check accuracy of test set\n",
    "print(\"Test set Accuracy: \", accuracy_score(Y_test, downsampledKNC_pred))\n",
    "print(\"Random Forest Classifier's f1_score: \",f1_score(Y_test, downsampledKNC_pred, average = 'weighted'))\n",
    "print(\"Random Forest Classifier's recall_score: \",recall_score(Y_test, downsampledKNC_pred, average = 'weighted'))\n",
    "print (classification_report(Y_test, downsampledKNC_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "SGD = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5).fit(X2_train, Y2_train)   \n",
    "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
    "           early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "           l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
    "           n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
    "           random_state=None, shuffle=True, tol=0.001,\n",
    "           validation_fraction=0.1, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD's Accuracy:  0.445326278659612\n",
      "SGD's f1_score:  0.36624465193346595\n",
      "SGD's recall_score:  0.445326278659612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.05      0.09       371\n",
      "           2       0.41      0.39      0.40       364\n",
      "           3       0.45      0.87      0.60       399\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      1134\n",
      "   macro avg       0.50      0.43      0.36      1134\n",
      "weighted avg       0.50      0.45      0.37      1134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Validate\n",
    "downsampledSGD_validate = SGD.predict(X2_validate)\n",
    "\n",
    "# Check the accuracy of validation set\n",
    "print(\"SGD's Accuracy: \", accuracy_score(Y2_validate, downsampledSGD_validate))\n",
    "print(\"SGD's f1_score: \",f1_score(Y2_validate, downsampledSGD_validate, average = 'weighted'))\n",
    "print(\"SGD's recall_score: \",recall_score(Y2_validate, downsampledSGD_validate, average = 'weighted'))\n",
    "print (classification_report(Y2_validate, downsampledSGD_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD's Accuracy:  0.23245958248312668\n",
      "SGD's f1_score:  0.2778371787336483\n",
      "SGD's recall_score:  0.23245958248312668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.03      0.07     70849\n",
      "           2       0.53      0.38      0.44     93875\n",
      "           3       0.01      0.88      0.02       922\n",
      "\n",
      "   micro avg       0.23      0.23      0.23    165646\n",
      "   macro avg       0.40      0.43      0.17    165646\n",
      "weighted avg       0.58      0.23      0.28    165646\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict on test set\n",
    "downsampledSGD_pred = SGD.predict(X_test)\n",
    "\n",
    "#Check the accuracy of test set\n",
    "print(\"SGD's Accuracy: \", accuracy_score(Y_test, downsampledSGD_pred))\n",
    "print(\"SGD's f1_score: \",f1_score(Y_test, downsampledSGD_pred, average = 'weighted'))\n",
    "print(\"SGD's recall_score: \",recall_score(Y_test, downsampledSGD_pred, average = 'weighted'))\n",
    "print (classification_report(Y_test, downsampledSGD_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
